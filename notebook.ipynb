{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from math import log10\n",
    "\n",
    "def PSNR(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if(mse == 0):  # MSE is zero means no noise is present in the signal .\n",
    "                  # Therefore PSNR have no importance.\n",
    "        return 100\n",
    "    max_pixel = 255.0\n",
    "    psnr = 10 * log10(max_pixel**2 / mse)\n",
    "    return psnr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "similarity = ssim(img1, img2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class DehazingDataset(data.Dataset):\n",
    "    def __init__(self, hazy_images_path, clean_images_path, transform=None):\n",
    "        #Get the images\n",
    "        self.hazy_images = [hazy_images_path + f for f in os.listdir(hazy_images_path) if  f.endswith('.jpg') or f.endswith('.png') or f.endswith('.jpeg')]\n",
    "        self.clean_images = [clean_images_path + f for f in os.listdir(clean_images_path) if f.endswith('.jpg') or f.endswith('.png') or f.endswith('.jpeg')]\n",
    "\n",
    "        #Filter the images to ensure they are counterparts of the same scene\n",
    "        self.filter_files()\n",
    "        self.size = len(self.hazy_images)\n",
    "        self.transform=transform\n",
    "    \n",
    "    def filter_files(self):\n",
    "        assert len(self.hazy_images) == len(self.clean_images)\n",
    "        hazy_ims = []\n",
    "        clean_ims = []\n",
    "        for hazy_img_path, clean_img_path in zip(self.hazy_images, self.clean_images):\n",
    "            hazy = Image.open(hazy_img_path)\n",
    "            clean = Image.open(clean_img_path)\n",
    "            if hazy.size == clean.size:\n",
    "                hazy_ims.append(hazy_img_path)\n",
    "                clean_ims.append(clean_img_path)\n",
    "        self.hazy_images = hazy_ims\n",
    "        self.clean_images = clean_ims\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        hazy_img = self.rgb_loader(self.hazy_images[index])\n",
    "        clean_img = self.rgb_loader(self.clean_images[index])\n",
    "        hazy_img = self.transform(hazy_img)\n",
    "        clean_img = self.transform(clean_img)\n",
    "        return hazy_img, clean_img\n",
    "\n",
    "    def rgb_loader(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            img = Image.open(f)\n",
    "            return img.convert('RGB')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "#Main code for dataloader\n",
    "\n",
    "hazy_path = \"/path/to/train/hazy/images/\"\n",
    "clean_path = \"/path/to/train/clean/images/\"\n",
    "transforms = transforms.Compose([\n",
    "                                 transforms.Resize((224, 224)),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "                                 ])\n",
    "dataset = DehazingDataset(hazy_path, clean_path, transform = transforms)\n",
    "data_loader = data.DataLoader(dataset=dataset,\n",
    "                              batch_size=32,\n",
    "                              shuffle=True,\n",
    "                              num_workers=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}